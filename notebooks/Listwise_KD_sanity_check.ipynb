{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57461396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f68e4",
   "metadata": {},
   "source": [
    "## CL-DRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd1b3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0890)\n",
      "tensor(1.1732)\n",
      "tensor(0.6311)\n",
      "tensor(inf)\n"
     ]
    }
   ],
   "source": [
    "def lambda_mrr_loss(y_pred, y_true, eps=1e-10, padded_value_indicator=-1, reduction=\"mean\", sigma=1.):\n",
    "    \"\"\"\n",
    "    y_pred: FloatTensor [bz, topk]\n",
    "    y_true: FloatTensor [bz, topk]\n",
    "    \"\"\"\n",
    "    device = y_pred.device\n",
    "    y_pred = y_pred.clone()\n",
    "    y_true = y_true.clone()\n",
    "\n",
    "    padded_mask = y_true == padded_value_indicator\n",
    "    y_pred[padded_mask] = float(\"-inf\")\n",
    "    y_true[padded_mask] = float(\"-inf\")\n",
    "\n",
    "    # Here we sort the true and predicted relevancy scores.\n",
    "    y_pred_sorted, indices_pred = y_pred.sort(descending=True, dim=-1)\n",
    "\n",
    "    # After sorting, we can mask out the pairs of indices (i, j) containing index of a padded element.\n",
    "    true_sorted_by_preds = torch.gather(y_true, dim=1, index=indices_pred)\n",
    "    true_diffs = true_sorted_by_preds[:, :, None] - true_sorted_by_preds[:, None, :]\n",
    "    padded_pairs_mask = torch.isfinite(true_diffs)\n",
    "    padded_pairs_mask = padded_pairs_mask & (true_diffs > 0)\n",
    "\n",
    "\n",
    "    # Here we find the gains, discounts and ideal DCGs per slate.\n",
    "    inv_pos_idxs = 1. / torch.arange(1, y_pred.shape[1] + 1).to(device)\n",
    "    weights = torch.abs(inv_pos_idxs.view(1,-1,1) - inv_pos_idxs.view(1,1,-1)) # [1, topk, topk]\n",
    "\n",
    "    # We are clamping the array entries to maintain correct backprop (log(0) and division by 0)\n",
    "    scores_diffs = (y_pred_sorted[:, :, None] - y_pred_sorted[:, None, :])\n",
    "    scores_diffs.masked_fill(torch.isnan(scores_diffs), 0.)\n",
    "    losses = torch.log(1. + torch.exp(-scores_diffs)) * weights #[bz, topk, topk]\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        loss = torch.sum(losses[padded_pairs_mask])\n",
    "    elif reduction == \"mean\":\n",
    "        loss = torch.mean(losses[padded_pairs_mask])\n",
    "    else:\n",
    "        raise ValueError(\"Reduction method can be either sum or mean\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    y_true = torch.FloatTensor([[1.,1./2, 1./3, 0.,0., -1/2., -1.]])\n",
    "    y_pred_1 = torch.FloatTensor([[2.3, 1.2, 1.1, 0.5, 0.23, 0.21, 40]])\n",
    "    y_pred_2 = torch.FloatTensor([[0.5, 0.23, 2.3, 1.2, 1.1, 5, 20]])\n",
    "    \n",
    "    print(lambda_mrr_loss(y_pred_1, y_true))\n",
    "    print(lambda_mrr_loss(y_pred_2, y_true))\n",
    "    \n",
    "    y_true_batch = torch.FloatTensor([[1.,1./2, 1./3, 0.,0., -1/2., -1.],[1.,1./2, 1./3, 0.,0., -1/2., -1.]])\n",
    "    y_pred_batch = torch.FloatTensor([[2.3, 1.2, 1.1, 0.5, 0.23, 0.21, 40],[0.5, 0.23, 2.3, 1.2, 1.1, 5, 20]])\n",
    "   \n",
    "    print(lambda_mrr_loss(y_pred_batch, y_true_batch))\n",
    "    \n",
    "    y_true = torch.FloatTensor([[1.,1./2, 1./3, 0.,0., -1/2., -1.]])\n",
    "    y_pred = torch.FloatTensor([[20.3, 10.2, 10.1, 50, 100, 21, 40]])\n",
    "    \n",
    "    print(lambda_mrr_loss(y_pred, y_true))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a487a6",
   "metadata": {},
   "source": [
    "## Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6016c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0890)\n",
      "tensor(1.1732)\n",
      "tensor(0.6311)\n",
      "tensor(17.3262)\n"
     ]
    }
   ],
   "source": [
    "def lambda_mrr_loss(y_pred, y_true, eps=1e-10, padded_value_indicator=-1, reduction=\"mean\", sigma=1.):\n",
    "    \"\"\"\n",
    "    y_pred: FloatTensor [bz, topk]\n",
    "    y_true: FloatTensor [bz, topk]\n",
    "    \"\"\"\n",
    "    device = y_pred.device\n",
    "    y_pred = y_pred.clone()\n",
    "    y_true = y_true.clone()\n",
    "\n",
    "    padded_mask = y_true == padded_value_indicator\n",
    "    y_pred[padded_mask] = float(\"-inf\")\n",
    "    y_true[padded_mask] = float(\"-inf\")\n",
    "\n",
    "    # Here we sort the true and predicted relevancy scores.\n",
    "    y_pred_sorted, indices_pred = y_pred.sort(descending=True, dim=-1)\n",
    "\n",
    "    # After sorting, we can mask out the pairs of indices (i, j) containing index of a padded element.\n",
    "    true_sorted_by_preds = torch.gather(y_true, dim=1, index=indices_pred)\n",
    "    true_diffs = true_sorted_by_preds[:, :, None] - true_sorted_by_preds[:, None, :]\n",
    "    padded_pairs_mask = torch.isfinite(true_diffs)\n",
    "    padded_pairs_mask = padded_pairs_mask & (true_diffs > 0)\n",
    "\n",
    "\n",
    "    # Here we find the gains, discounts and ideal DCGs per slate.\n",
    "    inv_pos_idxs = 1. / torch.arange(1, y_pred.shape[1] + 1).to(device)\n",
    "    weights = torch.abs(inv_pos_idxs.view(1,-1,1) - inv_pos_idxs.view(1,1,-1)) # [1, topk, topk]\n",
    "\n",
    "    # We are clamping the array entries to maintain correct backprop (log(0) and division by 0)\n",
    "    scores_diffs = (y_pred_sorted[:, :, None] - y_pred_sorted[:, None, :])\n",
    "    \n",
    "    topk = scores_diffs.size(1)\n",
    "    scores_diffs=scores_diffs.view(1,-1,1)\n",
    "\n",
    "    scores_diffs=F.pad(input=-scores_diffs, pad=(0,1), mode='constant', value=0)\n",
    "    scores = torch.logsumexp(scores_diffs,2,True)\n",
    "    scores = scores.view(-1,topk,topk)\n",
    "\n",
    "    losses =  scores * weights #[bz, topk, topk]\n",
    "\n",
    "    if reduction == \"sum\":\n",
    "        loss = torch.sum(losses[padded_pairs_mask])\n",
    "    elif reduction == \"mean\":\n",
    "        loss = torch.mean(losses[padded_pairs_mask])\n",
    "    else:\n",
    "        raise ValueError(\"Reduction method can be either sum or mean\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    y_true = torch.FloatTensor([[1.,1./2, 1./3, 0.,0., -1/2., -1.]])\n",
    "    y_pred_1 = torch.FloatTensor([[2.3, 1.2, 1.1, 0.5, 0.23, 0.21, 40]])\n",
    "    y_pred_2 = torch.FloatTensor([[0.5, 0.23, 2.3, 1.2, 1.1, 5, 20]])\n",
    "    \n",
    "    print(lambda_mrr_loss(y_pred_1, y_true))\n",
    "    print(lambda_mrr_loss(y_pred_2, y_true))\n",
    "    \n",
    "    y_true_batch = torch.FloatTensor([[1.,1./2, 1./3, 0.,0., -1/2., -1.],[1.,1./2, 1./3, 0.,0., -1/2., -1.]])\n",
    "    y_pred_batch = torch.FloatTensor([[2.3, 1.2, 1.1, 0.5, 0.23, 0.21, 40],[0.5, 0.23, 2.3, 1.2, 1.1, 5, 20]])\n",
    "   \n",
    "    print(lambda_mrr_loss(y_pred_batch, y_true_batch))\n",
    "    \n",
    "    y_true = torch.FloatTensor([[1.,1./2, 1./3, 0.,0., -1/2., -1.]])\n",
    "    y_pred = torch.FloatTensor([[20.3, 10.2, 10.1, 50, 100, 21, 40]])\n",
    "    \n",
    "    print(lambda_mrr_loss(y_pred, y_true))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fa693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dpr_speech)",
   "language": "python",
   "name": "dpr_speech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
