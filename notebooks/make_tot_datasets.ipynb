{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef9ce86-b94e-41d8-9601-9329bded77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d4f476-5949-4646-8de0-040de3fca5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7aea504-3f95-4da8-a27d-ff969adcae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from transformers import AutoConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3236a8f8-9910-4b80-9b3e-ef63c29231d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../datasets/ToT/trec-corpus/cache-192251ea7652b11c.arrow\n",
      "Loading cached processed dataset at ../datasets/ToT/trec-dev/cache-097ef614d33a8d0f.arrow\n",
      "Loading cached processed dataset at ../datasets/ToT/trec-corpus/cache-192251ea7652b11c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t trec-dev nQ: 150 nQToks: 25384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b80e0121b9948ea8c6e1d299e2b2c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/933 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (920 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t reddit-test nQ: 933 nQToks: 145325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nQ</th>\n",
       "      <th>nD</th>\n",
       "      <th>nQToks</th>\n",
       "      <th>nDToks</th>\n",
       "      <th>avgQLen</th>\n",
       "      <th>avgDLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TREC-ToT dev</td>\n",
       "      <td>150</td>\n",
       "      <td>231852</td>\n",
       "      <td>25384</td>\n",
       "      <td>154600886</td>\n",
       "      <td>169.226667</td>\n",
       "      <td>666.808507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RedditTest</td>\n",
       "      <td>933</td>\n",
       "      <td>231852</td>\n",
       "      <td>145325</td>\n",
       "      <td>154600886</td>\n",
       "      <td>155.760986</td>\n",
       "      <td>666.808507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name   nQ      nD  nQToks     nDToks     avgQLen     avgDLen\n",
       "0  TREC-ToT dev  150  231852   25384  154600886  169.226667  666.808507\n",
       "1    RedditTest  933  231852  145325  154600886  155.760986  666.808507"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_statistics(name, corpus, query_splits, tokenizer_name=\"distilbert-base-uncased\"):\n",
    "\n",
    "    def count_tokens(dataset, field):\n",
    "        counts = dataset.map(lambda _: {\"n_toks\": len(tokenizer(_[field])[\"input_ids\"])})\n",
    "        return np.sum(counts[\"n_toks\"])\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    if corpus:\n",
    "        corpus = datasets.load_from_disk(corpus)\n",
    "        nD = len(corpus)\n",
    "        nDToks = count_tokens(corpus, \"text\")\n",
    "    else:\n",
    "        nD = None\n",
    "        nDToks = None\n",
    "        \n",
    "    queries = {}\n",
    "    nQ = 0\n",
    "    nQToks = 0\n",
    "    for split, path in query_splits.items():\n",
    "        query = datasets.load_from_disk(path)\n",
    "        t = count_tokens(query, \"query\")\n",
    "        print(\"\\t\", split, \"nQ:\", len(query), \"nQToks:\", t)\n",
    "        \n",
    "        nQ += len(query)\n",
    "        nQToks += t\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"nQ\": nQ,\n",
    "        \"nD\": nD,\n",
    "        \"nQToks\": nQToks,\n",
    "        \"nDToks\": nDToks\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "d_stats = []\n",
    "d_stats.append(get_statistics(\"TREC-ToT dev\", corpus_path, trec_queries))\n",
    "d_stats.append(get_statistics(\"RedditTest\", corpus_path, reddit_queries))\n",
    "d_stats = pd.DataFrame(d_stats)\n",
    "d_stats[\"avgQLen\"] = d_stats[\"nQToks\"] / d_stats[\"nQ\"]\n",
    "d_stats[\"avgDLen\"] = d_stats[\"nDToks\"] / d_stats[\"nD\"]\n",
    "d_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392074e7-4b21-4704-bd20-39d0a9625207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbb78da-58fc-49cb-bb81-3d952f11b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_run import evaluate, compute_and_merge_mrr_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf8ff38-0df1-41ac-8870-a7f26d853b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST_PATH = Path(\"../datasets/ToT\")\n",
    "trec_tot_dataset_path = Path(\"/Users/sam/workspaces/trec-tot-repos/trec-tot/datasets/TREC-TOT/public/\")\n",
    "trec_tot_dataset_path_private = Path(\"/Users/sam/workspaces/trec-tot-repos/trec-tot/datasets/TREC-TOT/private/\")\n",
    "reddit_path = Path(\"/Users/sam/workspaces/tomt-data/trec_dataset/Movies/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc1b1f7-5bc5-4b1e-aa2e-bf677aef5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels = {}\n",
    "splits = {\"dev\", \"test\", \"train\"}\n",
    "\n",
    "trec_queries = {}\n",
    "\n",
    "def conv_q_trec_to_tev(q):\n",
    "    return {\n",
    "        \"query_id\": q[\"id\"],\n",
    "        \"query\": q[\"title\"] + \".\\n\" + q[\"text\"],\n",
    "        \"positive_passages\": [],\n",
    "        \"negative_passages\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "def conv_d_trec_to_tev(d):\n",
    "    return {\n",
    "        \"docid\": d[\"doc_id\"],\n",
    "        \"title\": d[\"page_title\"],\n",
    "        \"text\": d[\"text\"]\n",
    "    }\n",
    "\n",
    "def serial_dict(l):\n",
    "    d = defaultdict(list)\n",
    "    for _ in l:\n",
    "        for k, v in _.items():\n",
    "            d[k].append(v)\n",
    "    return d\n",
    "    \n",
    "\n",
    "    \n",
    "for split in splits:\n",
    "    queries = []\n",
    "    qrel = {}\n",
    "    q_path = trec_tot_dataset_path if split != \"test\" else trec_tot_dataset_path_private\n",
    "    with open(q_path / split / \"queries.jsonl\") as reader:\n",
    "        for line in reader:\n",
    "            q = json.loads(line)\n",
    "            queries.append(conv_q_trec_to_tev(q))\n",
    "\n",
    "            qrel[q[\"id\"]] = {\n",
    "                q[\"wikipedia_id\"] : 1\n",
    "            }\n",
    "    \n",
    "    qrels[f\"trec-{split}\"] = qrel\n",
    "    trec_dset = datasets.Dataset.from_dict(serial_dict(queries))\n",
    "    # trec_dset.save_to_disk(DEST_PATH / f\"trec-{split}\")\n",
    "\n",
    "    \n",
    "\n",
    "splits = {\"validation\", \"test\", \"train\"}\n",
    "for split in splits:\n",
    "    queries = []\n",
    "    qrel = {}\n",
    "    with open(reddit_path / f\"{split}.jsonl\") as reader:\n",
    "        for line in reader:\n",
    "            q = json.loads(line)\n",
    "            queries.append(conv_q_trec_to_tev(q))\n",
    "            qrel[q[\"id\"]] = {\n",
    "                q[\"wikipedia_id\"] : 1\n",
    "            }\n",
    "    \n",
    "    qrels[f\"reddit-{split}\"] = qrel\n",
    "\n",
    "    trec_dset = datasets.Dataset.from_dict(serial_dict(queries))\n",
    "    # trec_dset.save_to_disk(DEST_PATH / f\"reddit-{split}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0215795c-b452-4a5c-8c38-c7bba696bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trec_tot_dataset_path / \"corpus.jsonl\") as reader:\n",
    "    corpus = []\n",
    "    for line in reader:\n",
    "        corpus.append(conv_d_trec_to_tev(json.loads(line)))\n",
    "\n",
    "    trec_corpus = datasets.Dataset.from_dict(serial_dict(corpus))\n",
    "    # trec_corpus.save_to_disk(DEST_PATH / \"trec-corpus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb436cb9-efa2-4760-b689-92e2024e5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = DEST_PATH / \"trec-corpus\"\n",
    "trec_queries = {\n",
    "    #\"trec-train\": DEST_PATH / \"trec-train\",\n",
    "    \"trec-dev\": DEST_PATH / \"trec-dev\",\n",
    "    #\"trec-test\": DEST_PATH / \"trec-test\",\n",
    "}\n",
    "\n",
    "reddit_queries = {\n",
    "    \"reddit-test\": DEST_PATH / \"reddit-test\"\n",
    "}\n",
    "\n",
    "\n",
    "get_statistics("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b87febf-c244-4150-b3bf-cf8a43f9ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_runs(runs_folder: Path, metrics):\n",
    "    results = {}\n",
    "    for split, qrel in qrels.items():\n",
    "        run = defaultdict(dict)\n",
    "        with open(runs_folder / f\"tot-{split}.run\") as reader:\n",
    "            for line in reader:\n",
    "                qid, doc_id, score = line.split()\n",
    "                run[qid][doc_id] = float(score)\n",
    "    \n",
    "        mrr_cut = [_ for _ in metrics if _.startswith(\"recip_rank_cut_\")]\n",
    "        metrics = [_ for _ in metrics if _ not in mrr_cut]\n",
    "        assert len(qrel) == len(run)\n",
    "        assert [_ in run for _ in qrel]\n",
    "        eval_res_queries = evaluate(run, qrel, metrics)\n",
    "        # compute the MRR@K by cutting off the run at K, because trec_eval doesn't support @K\n",
    "        agg, eval_res_queries = compute_and_merge_mrr_cut(run, qrel, mrr_cut, eval_res_queries)\n",
    "    \n",
    "        eval_res = {}\n",
    "        for metric, values in agg.items():\n",
    "            m, s = (np.mean(values), np.std(values))\n",
    "            eval_res[metric] = m\n",
    "        results[split] = eval_res\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "108a2884-14cc-430f-b4e9-69b8617a5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"DPR\":  Path(\"./gathered_results/dpr_hs_db_3_runs/\"),\n",
    "    \"TAS-B (0s)\":  Path(\"./gathered_results/tas_b_zeroshot_runs/\"), \n",
    "    \"MVRL\": Path(\"./gathered_results_manual/MVRL_new_tot/\"),\n",
    "    \"CLDRD\": Path(\"./gathered_results/cldrd_runs/\")\n",
    "}\n",
    "\n",
    "METRICS = {\"recip_rank\", \"ndcg_cut_10\", \"ndcg_cut_1000\", \"recall_1000\"}\n",
    "\n",
    "sel_splits = {\"reddit-test\", \"trec-dev\"}\n",
    "\n",
    "result_rows = []\n",
    "for model, run_folder in MODELS.items():\n",
    "    row = {\"model\": model}\n",
    "    for sp, sp_res in evaluate_runs(run_folder, METRICS).items():\n",
    "        if sp not in sel_splits: continue\n",
    "        for m, v in sp_res.items():\n",
    "            row[f\"{sp}-{m}\"] = v\n",
    "    result_rows.append(row)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(result_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e31dc26-1d78-49a1-abd9-4cba70e1767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d18f34f-3dd6-4a94-9d51-19dc0aa7d9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>trec-dev-recip_rank</th>\n",
       "      <th>trec-dev-recall_1000</th>\n",
       "      <th>trec-dev-ndcg_cut_10</th>\n",
       "      <th>trec-dev-ndcg_cut_1000</th>\n",
       "      <th>reddit-test-recip_rank</th>\n",
       "      <th>reddit-test-recall_1000</th>\n",
       "      <th>reddit-test-ndcg_cut_10</th>\n",
       "      <th>reddit-test-ndcg_cut_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DPR</td>\n",
       "      <td>0.041916</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.040119</td>\n",
       "      <td>0.082610</td>\n",
       "      <td>0.026075</td>\n",
       "      <td>0.359057</td>\n",
       "      <td>0.028314</td>\n",
       "      <td>0.072324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAS-B (0s)</td>\n",
       "      <td>0.064457</td>\n",
       "      <td>0.453333</td>\n",
       "      <td>0.068048</td>\n",
       "      <td>0.118594</td>\n",
       "      <td>0.077386</td>\n",
       "      <td>0.524116</td>\n",
       "      <td>0.088931</td>\n",
       "      <td>0.146284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MVRL</td>\n",
       "      <td>0.033553</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.035671</td>\n",
       "      <td>0.055117</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.275456</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>0.058864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLDRD</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.059676</td>\n",
       "      <td>0.103649</td>\n",
       "      <td>0.056972</td>\n",
       "      <td>0.443730</td>\n",
       "      <td>0.063539</td>\n",
       "      <td>0.115164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model  trec-dev-recip_rank  trec-dev-recall_1000  \\\n",
       "0         DPR             0.041916              0.340000   \n",
       "1  TAS-B (0s)             0.064457              0.453333   \n",
       "2        MVRL             0.033553              0.193333   \n",
       "3       CLDRD             0.057906              0.393333   \n",
       "\n",
       "   trec-dev-ndcg_cut_10  trec-dev-ndcg_cut_1000  reddit-test-recip_rank  \\\n",
       "0              0.040119                0.082610                0.026075   \n",
       "1              0.068048                0.118594                0.077386   \n",
       "2              0.035671                0.055117                0.024213   \n",
       "3              0.059676                0.103649                0.056972   \n",
       "\n",
       "   reddit-test-recall_1000  reddit-test-ndcg_cut_10  reddit-test-ndcg_cut_1000  \n",
       "0                 0.359057                 0.028314                   0.072324  \n",
       "1                 0.524116                 0.088931                   0.146284  \n",
       "2                 0.275456                 0.027088                   0.058864  \n",
       "3                 0.443730                 0.063539                   0.115164  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcc776-9628-4401-a7ff-61082f86cd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
