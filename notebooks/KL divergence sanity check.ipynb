{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bb38b7-f09e-4de4-80e2-dd5f130334f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f640dae8-585c-416a-88ac-92b2fe372b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm, qv = torch.rand(1, 5), torch.rand(1, 5)\n",
    "dm, dv = torch.rand(3, 5).exp(), torch.rand(3, 5).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed557b06-e642-46b9-baad-efb75b747c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth for KL divergence: tensor([[-4.1362, -4.1960, -3.5086]])\n"
     ]
    }
   ],
   "source": [
    "def pytorch_kld(qmean, qvar, dmean, dvar):\n",
    "    kl = torch.zeros(qmean.size(0), dmean.size(0), device=qmean.device)\n",
    "    p = []\n",
    "    q = []\n",
    "    for i in range(qmean.size(0)):\n",
    "        q.append(MultivariateNormal(qmean[i, :], covariance_matrix=torch.diag(qvar[i, :])))\n",
    "    for i in range(dmean.size(0)):\n",
    "        p.append(MultivariateNormal(dmean[i, :], covariance_matrix=torch.diag(dvar[i, :])))\n",
    "    for (i, j) in np.ndindex(len(q), len(p)):\n",
    "        kl[i, j] = -1 * torch.distributions.kl_divergence(q[i], p[j])\n",
    "    return kl\n",
    "\n",
    "print(\"Ground truth for KL divergence:\", pytorch_kld(qm, qv, dm, dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369215e4-1274-425e-bbb7-13699f1ef804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same output as 'pytorch_kld(qm, qv, dm, dv)': tensor([-4.1362, -4.1960, -3.5086])\n",
      "Constants removed: tensor([-11.4154, -11.5351, -10.1603])\n"
     ]
    }
   ],
   "source": [
    "def mrl_eq10_kld(qmean, qvar, dmean, dvar, remove_constants=False):\n",
    "    \"\"\" Constants = k, 0.5, torch.log(qvar).sum() (constant w.r.t. document ranking).\n",
    "        If remove_constants=True, we get Eq. 10 from MRL paper.\n",
    "        If remove_constants=False, we get the same implementation as pytorch_kld.\n",
    "    \"\"\"\n",
    "    k = qmean.size(1)\n",
    "    logvar_ratio_term = torch.log(dvar).sum(1)\n",
    "    if not remove_constants:\n",
    "        logvar_ratio_term -= torch.log(qvar).sum(1)\n",
    "    trace_term = (qvar / dvar).sum(1)\n",
    "    square_term = ((qmean - dmean)**2 / dvar).sum(1)\n",
    "    kld = logvar_ratio_term + trace_term + square_term\n",
    "    if not remove_constants:\n",
    "        kld = 0.5 * (kld - k)\n",
    "    return -kld\n",
    "\n",
    "print(\"Same output as 'pytorch_kld(qm, qv, dm, dv)':\", mrl_eq10_kld(qm, qv, dm, dv))\n",
    "print(\"Constants removed:\", mrl_eq10_kld(qm, qv, dm, dv, remove_constants=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72730f12-f3d6-437b-939e-dbaac137d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same output as 'mrl_eq10_kld(qm, qv, dm, dv, remove_constants=True)': tensor([[-11.4154, -11.5351, -10.1603]])\n"
     ]
    }
   ],
   "source": [
    "def mrl_query_rep(qmean, qvar):\n",
    "    batch_size = qmean.size(0)\n",
    "    k = qmean.size(1)\n",
    "    rep = torch.zeros(batch_size, 1 + 3 * k, device=qmean.device)\n",
    "    rep[:, 0] = 1\n",
    "    rep[:, 1:k + 1] = qvar\n",
    "    rep[:, k + 1:2 * k + 1] = qmean ** 2\n",
    "    rep[:, 2 * k + 1:] = qmean\n",
    "    return rep\n",
    "\n",
    "def mrl_document_rep(dmean, dvar):\n",
    "    batch_size = dmean.size(0)\n",
    "    k = dmean.size(1)\n",
    "    rep = torch.zeros(batch_size, 1 + 3 * k, device=dmean.device)\n",
    "    rep[:, 0] = - (torch.log(dvar) + dmean**2 / dvar).sum(1)\n",
    "    rep[:, 1:k + 1] = - 1 / dvar\n",
    "    rep[:, k + 1:2 * k + 1] = - 1 / dvar\n",
    "    rep[:, 2 * k + 1:] = (2 * dmean) / dvar\n",
    "    return rep\n",
    "\n",
    "def mrl_dot_product(qmean, qvar, dmean, dvar):\n",
    "    qrep = mrl_query_rep(qmean, qvar)\n",
    "    drep = mrl_document_rep(dmean, dvar)\n",
    "    return qrep @ drep.T\n",
    "    # return torch.einsum(\"ij,jk->k\", qrep, drep.T)\n",
    "\n",
    "print(\"Same output as 'mrl_eq10_kld(qm, qv, dm, dv, remove_constants=True)':\", mrl_dot_product(qm, qv, dm, dv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
