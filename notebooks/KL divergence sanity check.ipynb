{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bb38b7-f09e-4de4-80e2-dd5f130334f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f640dae8-585c-416a-88ac-92b2fe372b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm, qv = torch.rand(2, 5), torch.rand(2, 5)\n",
    "dm, dv = torch.rand(3, 5).exp(), torch.rand(3, 5).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cbafd6-e083-41c1-a3fb-da2719253205",
   "metadata": {},
   "source": [
    "## KL divergence as computed by native PyTorch library.\n",
    "\n",
    "$\\DeclareMathOperator{\\kld}{KLD}$\n",
    "$\\DeclareMathOperator{\\trace}{tr}$\n",
    "$\\DeclareMathOperator{\\mean}{\\mu}$\n",
    "$\\DeclareMathOperator{\\cov}{\\Sigma}$\n",
    "\n",
    "\\begin{equation}\n",
    "    \\kld(Q \\| D) = \\frac{1}{2} \\Big[ \\log \\frac{\\det \\cov_D}{\\det \\cov_Q} - k + \\trace\\{\\cov_D^{-1}\\cov_Q\\} + (\\mean_Q - \\mean_D)^\\intercal \\cov_D^{-1}(\\mean_Q - \\mean_D) \\Big]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed557b06-e642-46b9-baad-efb75b747c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth for KL divergence:\n",
      "tensor([[-7.2569, -4.2285, -4.5962],\n",
      "        [-9.0958, -6.4639, -6.0405]])\n"
     ]
    }
   ],
   "source": [
    "def pytorch_kld(qmean, qvar, dmean, dvar):\n",
    "    kl = torch.zeros(qmean.size(0), dmean.size(0), device=qmean.device)\n",
    "    p = []\n",
    "    q = []\n",
    "    for i in range(qmean.size(0)):\n",
    "        q.append(MultivariateNormal(qmean[i, :], covariance_matrix=torch.diag(qvar[i, :])))\n",
    "    for i in range(dmean.size(0)):\n",
    "        p.append(MultivariateNormal(dmean[i, :], covariance_matrix=torch.diag(dvar[i, :])))\n",
    "    for (i, j) in np.ndindex(len(q), len(p)):\n",
    "        kl[i, j] = -1 * torch.distributions.kl_divergence(q[i], p[j])\n",
    "    return kl\n",
    "\n",
    "pytorch_kld_ = pytorch_kld(qm, qv, dm, dv)\n",
    "print(f\"Ground truth for KL divergence:\\n{pytorch_kld_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de268dfd-0d0a-484e-8c47-348c183bea26",
   "metadata": {},
   "source": [
    "## Simplified KL divergence scoring function as per Eq. 10 of MRL paper (corrected).\n",
    "\n",
    "\\begin{equation}\n",
    "    \\kld(Q \\| D) = \\sum_{i=1}^k \\log \\sigma^2_{i_D} + \\sum_{i=1}^k \\frac{\\sigma^2_{i_Q}}{\\sigma^2_{i_D}} + \\sum_{i=1}^k \\frac{\\mu_{i_Q}^2}{\\sigma^2_{i_D}} - \\sum_{i=1}^k \\frac{2\\mu_{i_Q}\\mu_{i_D}}{\\sigma^2_{i_D}} + \\sum_{i=1}^k \\frac{\\mu_{i_D}^2}{\\sigma^2_{i_D}}\n",
    "\\end{equation}\n",
    "\n",
    "Optional: `remove_constants=False` to get full KL divergence.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\kld(Q \\| D) = \\frac{1}{2} \\Bigg[ \\sum_{i=1}^k \\log \\sigma^2_{i_D} - \\sum_{i=1}^k \\log \\sigma^2_{i_Q} - k + \\sum_{i=1}^k \\frac{\\sigma^2_{i_Q}}{\\sigma^2_{i_D}} + \\sum_{i=1}^k \\frac{\\mu_{i_Q}^2}{\\sigma^2_{i_D}} - \\sum_{i=1}^k \\frac{2\\mu_{i_Q}\\mu_{i_D}}{\\sigma^2_{i_D}} + \\sum_{i=1}^k \\frac{\\mu_{i_D}^2}{\\sigma^2_{i_D}} \\Bigg]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "865d694b-b003-48ee-bb4e-e18ecc3b9b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same output as 'pytorch_kld(qm, qv, dm, dv)':\n",
      "tensor([[-7.2569, -4.2285, -4.5962],\n",
      "        [-9.0958, -6.4639, -6.0405]])\n",
      "Eq. 10 simplified, constants removed:\n",
      "tensor([[-15.9074,  -9.8506, -10.5861],\n",
      "        [-16.2117, -10.9480, -10.1012]])\n"
     ]
    }
   ],
   "source": [
    "def mrl_eq10_kld(qmean, qvar, dmean, dvar, remove_constants=False):\n",
    "    \"\"\" Constants = k, 0.5, torch.log(qvar).sum() (constant w.r.t. document ranking).\n",
    "        If remove_constants=True, we get Eq. 10 from MRL paper.\n",
    "        If remove_constants=False, we get the same implementation as pytorch_kld.\n",
    "    \"\"\"\n",
    "    k = qmean.size(1)\n",
    "    logvar_ratio_term = torch.log(dvar).sum(1)[None, :]\n",
    "    if not remove_constants:\n",
    "        logvar_ratio_term = logvar_ratio_term - torch.log(qvar).sum(1)[:, None]\n",
    "    trace_term = (qvar[:, None, :] / dvar[None, :, :]).sum(2)\n",
    "    square_term = ((qmean[:, None, :] - dmean[None, :, :])**2 / dvar[None, :, :]).sum(2)\n",
    "    kld = logvar_ratio_term + trace_term + square_term\n",
    "    if not remove_constants:\n",
    "        kld = 0.5 * (kld - k)\n",
    "    return -kld\n",
    "\n",
    "mrl_eq10_kld_ = mrl_eq10_kld(qm, qv, dm, dv)\n",
    "mrl_eq10_kld_simplified_ = mrl_eq10_kld(qm, qv, dm, dv, remove_constants=True)\n",
    "print(f\"Same output as 'pytorch_kld(qm, qv, dm, dv)':\\n{mrl_eq10_kld_}\")\n",
    "print(f\"Eq. 10 simplified, constants removed:\\n{mrl_eq10_kld_simplified_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4ec94-ce10-4db0-89f2-6081c4c0aa1f",
   "metadata": {},
   "source": [
    "## Simplified KL divergence scoring function as a dot product.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\kld(Q \\| D) = \\vec{q}^\\intercal \\cdot \\vec{d}\n",
    "\\end{equation}\n",
    "\\begin{align}\n",
    "    & \\vec{q} = \\Big[ 1, \\sigma^2_{1_Q}, \\dotsc, \\sigma^2_{k_Q}, \\mu_{1_Q}^2, \\dotsc, \\mu_{k_Q}^2, \\mu_{1_Q}, \\dotsc, \\mu_{k_Q} \\Big] \\\\\n",
    "    & \\vec{d} = \\Bigg[ \\gamma_{D}, \\frac{1}{\\sigma^2_{1_D}}, \\dotsc, \\frac{1}{\\sigma^2_{k_D}}, \\frac{1}{\\sigma^2_{1_D}}, \\dotsc, \\frac{1}{\\sigma^2_{k_D}}, -\\frac{2\\mu_{1_D}}{\\sigma^2_{1_D}}, \\dotsc, -\\frac{2\\mu_{k_D}}{\\sigma^2_{k_D}} \\Bigg]\n",
    "\\end{align}\n",
    "Where\n",
    "\\begin{equation}\n",
    "    \\gamma_{D} = \\sum_{i=1}^k \\Bigg( \\log \\sigma^2_{i_D} + \\frac{\\mu_{i_D}^2}{\\sigma^2_{i_D}} \\Bigg)\n",
    "\\end{equation}\n",
    "\n",
    "Output should be the same as Eq. 10 of MRL with constants removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72730f12-f3d6-437b-939e-dbaac137d4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same output as 'mrl_eq10_kld(qm, qv, dm, dv, remove_constants=True)':\n",
      "tensor([[-15.9074,  -9.8506, -10.5861],\n",
      "        [-16.2117, -10.9480, -10.1012]])\n"
     ]
    }
   ],
   "source": [
    "def mrl_query_rep(qmean, qvar):\n",
    "    batch_size = qmean.size(0)\n",
    "    k = qmean.size(1)\n",
    "    rep = torch.zeros(batch_size, 3 * k + 1, device=qmean.device)\n",
    "    rep[:, 0] = 1\n",
    "    rep[:, 1:k + 1] = qvar\n",
    "    rep[:, k + 1:2 * k + 1] = qmean ** 2\n",
    "    rep[:, 2 * k + 1:] = qmean\n",
    "    return rep\n",
    "\n",
    "def mrl_document_rep(dmean, dvar):\n",
    "    batch_size = dmean.size(0)\n",
    "    k = dmean.size(1)\n",
    "    rep = torch.zeros(batch_size, 3 * k + 1, device=dmean.device)\n",
    "    rep[:, 0] = - (torch.log(dvar) + dmean**2 / dvar).sum(1)\n",
    "    rep[:, 1:k + 1] = - 1 / dvar\n",
    "    rep[:, k + 1:2 * k + 1] = - 1 / dvar\n",
    "    rep[:, 2 * k + 1:] = (2 * dmean) / dvar\n",
    "    return rep\n",
    "\n",
    "def mrl_dot_product(qmean, qvar, dmean, dvar):\n",
    "    qrep = mrl_query_rep(qmean, qvar)\n",
    "    drep = mrl_document_rep(dmean, dvar)\n",
    "    return qrep @ drep.T\n",
    "\n",
    "mrl_dot_product_ = mrl_dot_product(qm, qv, dm, dv)\n",
    "print(f\"Same output as 'mrl_eq10_kld(qm, qv, dm, dv, remove_constants=True)':\\n{mrl_dot_product_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489a911-6c20-432b-8b82-e68a50ee7df5",
   "metadata": {},
   "source": [
    "## Full KL divergence as a dot product.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\kld(Q \\| D) = \\frac{1}{2} \\big(\\vec{q'}^\\intercal \\cdot \\vec{d'} - k \\big)\n",
    "\\end{equation}\n",
    "\\begin{align}\n",
    "    & \\vec{q'} = \\Big[ 1, \\gamma_{Q}, \\sigma^2_{1_Q}, \\dotsc, \\sigma^2_{k_Q}, \\mu_{1_Q}^2, \\dotsc, \\mu_{k_Q}^2, \\mu_{1_Q}, \\dotsc, \\mu_{k_Q} \\Big] \\\\\n",
    "    & \\vec{d'} = \\Bigg[ \\gamma_{D}, 1, \\frac{1}{\\sigma^2_{1_D}}, \\dotsc, \\frac{1}{\\sigma^2_{k_D}}, \\frac{1}{\\sigma^2_{1_D}}, \\dotsc, \\frac{1}{\\sigma^2_{k_D}}, -\\frac{2\\mu_{1_D}}{\\sigma^2_{1_D}}, \\dotsc, -\\frac{2\\mu_{k_D}}{\\sigma^2_{k_D}} \\Bigg]\n",
    "\\end{align}\n",
    "Where\n",
    "\\begin{equation}\n",
    "    \\gamma_{D} = \\sum_{i=1}^k \\Bigg( \\log \\sigma^2_{i_D} + \\frac{\\mu_{i_D}^2}{\\sigma^2_{i_D}} \\Bigg)\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "    \\gamma_{Q} = \\sum_{i=1}^k \\log \\sigma^2_{i_Q}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c6205f-d6fb-4269-926c-fe724314530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same output as 'pytorch_kld(qm, qv, dm, dv)':\n",
      "tensor([[-7.2569, -4.2285, -4.5962],\n",
      "        [-9.0958, -6.4639, -6.0405]])\n"
     ]
    }
   ],
   "source": [
    "def mrl_query_rep_full(qmean, qvar):\n",
    "    batch_size = qmean.size(0)\n",
    "    k = qmean.size(1)\n",
    "    rep = torch.zeros(batch_size, 3 * k + 2, device=qmean.device)\n",
    "    rep[:, 0] = 1\n",
    "    rep[:, 1] = torch.log(qvar).sum(1)\n",
    "    rep[:, 2:k + 2] = qvar\n",
    "    rep[:, k + 2:2 * k + 2] = qmean ** 2\n",
    "    rep[:, 2 * k + 2:] = qmean\n",
    "    return rep\n",
    "\n",
    "def mrl_document_rep_full(dmean, dvar):\n",
    "    batch_size = dmean.size(0)\n",
    "    k = dmean.size(1)\n",
    "    rep = torch.zeros(batch_size, 3 * k + 2, device=dmean.device)\n",
    "    rep[:, 0] = - (torch.log(dvar) + dmean**2 / dvar).sum(1)\n",
    "    rep[:, 1] = 1\n",
    "    rep[:, 2:k + 2] = - 1 / dvar\n",
    "    rep[:, k + 2:2 * k + 2] = - 1 / dvar\n",
    "    rep[:, 2 * k + 2:] = (2 * dmean) / dvar\n",
    "    return rep\n",
    "\n",
    "def mrl_dot_product_full(qmean, qvar, dmean, dvar):\n",
    "    k = qmean.size(1)\n",
    "    qrep = mrl_query_rep_full(qmean, qvar)\n",
    "    drep = mrl_document_rep_full(dmean, dvar)\n",
    "    return 0.5 * (qrep @ drep.T + k)\n",
    "\n",
    "mrl_dot_product_full_ = mrl_dot_product_full(qm, qv, dm, dv)\n",
    "print(f\"Same output as 'pytorch_kld(qm, qv, dm, dv)':\\n{mrl_dot_product_full_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a683f1f-9660-4075-b25f-e2b129dc2b7d",
   "metadata": {},
   "source": [
    "## Some final sanity checks for matching outputs.\n",
    "\n",
    "1. The formal definition of KL divergence (as per PyTorch implementation), should match the unsimplified version of the (corrected) Eq. 10 of the MRL paper.\n",
    "2. The simplified KL divergence-based scoring function in Eq. 10, should match its dot product formulation.\n",
    "3. The formal definition of KL divergence (as per PyTorch implementation), should match the dot product formulation of the unsimplified version of Eq. 10, that includes constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de735bf-25ab-474c-83c7-0217262cb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal definition of KL div. matches unsimplified version of Eq.10: True\n",
      "Simplified version of Eq. 10 matches dot product formulation: True\n",
      "Formal definition of KL div. matches dot product formulation including constants: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Formal definition of KL div. matches unsimplified version of Eq.10: {torch.allclose(pytorch_kld_, mrl_eq10_kld_)}\")\n",
    "print(f\"Simplified version of Eq. 10 matches dot product formulation: {torch.allclose(mrl_eq10_kld_simplified_, mrl_dot_product_)}\")\n",
    "print(f\"Formal definition of KL div. matches dot product formulation including constants: {torch.allclose(pytorch_kld_, mrl_dot_product_full_)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
